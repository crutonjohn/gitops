---
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: pod-logging
spec:
  mode: daemonset
  image: otel/opentelemetry-collector-contrib:0.96.0
  volumeMounts:
    - name: hostvarlog
      mountPath: /var/log
    - name: scratchdir
      mountPath: /var/lib/otelcol
  volumes:
    - name: hostvarlog
      hostPath:
        path: /var/log
        type: Directory
    - name: scratchdir
      emptyDir:
        sizeLimit: 10Gi
  resources:
    limits:
      cpu: 256m
      memory: 2Gi
  serviceAccount: collector
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  config: |
    receivers:
      filelog/0:
        include:
          - /var/log/pods/*/*/*.log
        exclude:
          - /var/log/pods/*/otc-container/*.log
        start_at: beginning
        storage: file_storage
        include_file_path: true
        include_file_name: false
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: 2006-01-02T15:04:05.999999999Z07:00
            layout_type: gotime
            parse_from: attributes.time
          type: regex_parser
        - combine_field: attributes.log
          combine_with: ""
          id: crio-recombine
          is_last_entry: attributes.logtag == 'F'
          max_log_size: 102400
          output: extract_metadata_from_filepath
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: parser-containerd
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: regex_parser
        - combine_field: attributes.log
          combine_with: ""
          id: containerd-recombine
          is_last_entry: attributes.logtag == 'F'
          max_log_size: 102400
          output: extract_metadata_from_filepath
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: parser-docker
          output: extract_metadata_from_filepath
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: json_parser
        - id: extract_metadata_from_filepath
          parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
          type: regex_parser
        - from: attributes.stream
          to: attributes["log.iostream"]
          type: move
        - from: attributes.container_name
          to: resource["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: resource["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: resource["k8s.pod.name"]
          type: move
        - from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
          type: move
        - from: attributes.uid
          to: resource["k8s.pod.uid"]
          type: move
        - from: attributes.log
          to: body
          type: move
        - type: add
          field: resource["cluster"]
          value: 'main-lyh' # Set your cluster name here
      filelog/1:
        include:
          - /var/log/syslog
        start_at: end
        storage: file_storage
        include_file_path: true
        include_file_name: false
        operators:
          #- type: regex_parser
          #  id: extract_hostname_from_log
          #  regex: '^\w+\s+\d+\s\d+:\d+:\d+\s(?P<host_name>[^_]+).*$'
          #  parse_from: attributes["log"]
          #- type: move
          #  from: attributes.host_name
          #  to: attributes["log.hostname"]
          - type: syslog_parser
            protocol: rfc5424
          - type: move
            from: attributes.log
            to: body
      otlp:
        protocols:
          grpc:
    processors:
      batch:
        send_batch_size: 4096
        timeout: 200ms
        send_batch_max_size: 0
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: K8S_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
            - container.id
          labels:
            - tag_name: key1
              key: label1
              from: pod
            - tag_name: key2
              key: label2
              from: pod
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.ip
          - sources:
              - from: resource_attribute
                name: k8s.pod.uid
          - sources:
              - from: connection
      resource/loki0:
        attributes:
          - action: insert
            key: loki.format
            value: raw
          - action: insert
            key: loki.resource.labels
            value: pod, namespace, container, cluster, filename
      resource/loki1:
        attributes:
          - action: insert
            key: loki.resource.labels
            value: event.domain, body.appname, body.facility, body.hostname, body.message, body.msg_id, body.priority, body.proc_id, body.severity
          - action: insert
            key: loki.format
            value: raw
    exporters:
      logging:
        loglevel: debug
      loki:
        endpoint: "http://100.64.0.4:3100/loki/api/v1/push"
        retry_on_failure:
          initial_interval: 5s
          max_interval: 15s
          max_elapsed_time: 30s
        sending_queue:
          enabled: true
          storage: file_storage
          num_consumers: 5
          queue_size: 300
    extensions:
      health_check:
        path: "/health/status"
        endpoint: ":13333"
      file_storage:
        directory: /var/lib/otelcol
        timeout: 1s
        compaction:
          on_start: true
          on_rebound: true
          directory: /var/lib/otelcol
          max_transaction_size: 65530
      memory_ballast:
        size_in_percentage: 30
    service:
      extensions:
        - health_check
        - file_storage
        - memory_ballast
      telemetry:
        metrics:
          address: "0.0.0.0:8888"
      pipelines:
        logs/0:
          receivers:
            - filelog/0
          processors:
            #- k8sattributes
            - resource/loki0
            - batch
          exporters:
            - loki
        logs/1:
          receivers:
            - otlp
            - filelog/1
          processors:
            - resource/loki1
            - batch
          exporters:
            - logging
            - loki
